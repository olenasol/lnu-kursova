\documentclass[12pt]{report}
\usepackage{titlesec}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{makecell}

\usepackage{amssymb}
\graphicspath{{pictures/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\usepackage{cmap} 
\usepackage[T2A]{fontenc} 
\usepackage[utf8]{inputenc} 
\usepackage[english, ukrainian]{babel} 
\textheight=24cm 
\textwidth=16cm 
\oddsidemargin=0pt 
\topmargin=-2.5cm
\parindent=24pt 
\parskip=0pt 
\tolerance=2000 
\flushbottom 



\begin{document}
\begin{titlepage}
\begin{center}
	\normalsize{MІНІСТЕРСТВО ОСВІТИ І НАУКИ УКРАЇНИ}\\\vspace*{0.2cm}
\small{\textbf{ЛЬВІВСЬКИЙ НАЦІОНАЛЬНИЙ УНІВЕРСИТЕТ ІМЕНІ ІВАНА ФРАНКА}
	\vspace*{0.2cm}\\\normalsize{ Факультет прикладної математики та інформатики\\\vspace*{0.2cm}Кафедра обчислювальної математики}}\\
\end{center}
\vspace*{3cm}
\begin{center}

\Large{\textbf{Магістерська робота}}\\
\vspace*{0.5cm}
\large{Реалізація алгоритму розв'язування
		інтегральних рівнянь та задачі Діріхле для
		рівняння Лапласа використовуючи ієрархічні
		матриці}
\end{center}
\normalsize
\vspace*{4cm}\hspace*{8cm}Виконала: студентка групи ПмП-61 \\
\hspace*{8cm}спеціальності \\
\hspace*{8cm}113 - прикладна математика\\
\hspace*{8cm}Солук О.О.\\

\hspace*{7.1cm}Керівник Вавричук В.Г.\\
\\
\hspace*{7.9cm}Рецензент $\underline{ \quad \quad\quad\quad\quad\quad\quad\quad}$\\
\vspace*{4cm}
\begin{center}
Львів - 2019
\end{center}
\end{titlepage}
\newpage
	\tableofcontents
\titleformat
{\chapter}[display]
{\bf\Large}{}
{0.5ex}
{
	\vspace{-0.5ex}
}[\vspace{-0.5ex}]
\newpage
\chapter{1. Вступ.}
	\hspace{0.8cm} Ієрархічна матриця ($\mathcal{H}$-матриця) використовується для апроксимації розрідженими даними щільних матриць. Ці матриці застосовують коли намагаються розв'язати систему лінійних рівнянь
	
	 $$ Ax=b \quad\quad  A \in \mathbb{R}^{n\times n} ,\quad   x\in \mathbb{R}^n$$ \newline
	 з майже лінійною складністю $O(n\log(n))$. Операції з $\mathcal{H}$-матрицею дають наближення. Проте похибки наближення є прийнятними, оскільки великомасштабні матриці зазвичай отримують в результаті дискретизацій, які так чи інакше містять похибку дискретизації. Ці твердження не стосуються всіх матриць, але вони справедливі для важливого класу матриць, що сформовані внаслідок стандартних дискретизацій еліптичних рівнянь або інтегральних рівнянь. 
	 \par Вперше концепцію ієрахічних матриць запропонував Вольфганг Хакбуш  в 1998 році. Вiн розширив iдею панельних кластерних методів, зробивши її застосовною до загальних алгебраїчних операцій над матрицями, оберненими матрицями тощо. 
	 \par В цій роботі розглянуто базові означення та процес побудови $\mathcal{H}$-матриць, їх застосування на прикладі одновимірної модельної задачі, для розв'язування якої використовують метод граничних елементів (BEM - boundary element method). Введено означення ієрархічних матриць для  багатовимірного випадку. Розглянуто двовимірний випадок на прикладі задачі Діріхле для рівняння Лапласа.
	 \par Текст цієї роботи написано на основі матеріалів \cite{HM},\cite{Diss}. Також, деякі графічні ілюстрації взяті з роботи \cite{HM}.
	 
	
\newpage
\chapter{2. Обчислення за допомогою ієрархічних матриць.}
	\section{Означення кластерного дерева.}
	\newtheorem{Def}{Означення}[chapter]
	\begin{Def}
	{\bf (Дерево)} Нехай $V$ - непорожня множина і $E\subseteq V\times V$ є бінарним відношенням над $V$. Пара $\mathbb{T}=(V,E)$, де множина $V=V(\mathbb{T})$ є множиною вершин $\mathbb{T}$, а множина $E=E(\mathbb{T})$ - множина ребер $\mathbb{T}$, називається деревом, якщо виконуються такі умови:
	\begin{enumerate}
		\item[-] Унікальна вершина $v\in V$ називається коренем дерева і позначається $root(\mathbb{T})$ $\Leftrightarrow \forall w\in V:w\not=v$ виконується $(w,v)\not\in E$.
		\item[-] Для будь-якої вершини $v\in V\backslash root(\mathbb{T})$ існує єдиний простий шлях з $root(\mathbb{T})$ до $v$.
	\end{enumerate}

	\end{Def}
	Іншими словами, дерево - це неорієнтований зв'язний граф без простих циклів.
	\par Введемо такі позначення:
	\begin{enumerate}
		\item[$\bullet$] Для вершини $v\in V$ множина її синів визначається як $$S(v)=\{w\in V |(v,w)\in E \}$$
		\item[$\bullet$] Множину всіх листків дерева $\mathbb{T}$ визначають як $\mathcal{L}(\mathbb{T})=\{v\in V|S(v)=\O \}$
		\item[$\bullet$] Рівень дерева $\mathbb{T}$ визначається рекурсивно як $$\mathbb{T}^{(0)}=root(\mathbb{T})$$
		$$\mathbb{T}^{(l)}=\{v \in V|\exists w\in \mathbb{T}^{(l-1)}:(w,v)\in E\}$$
		Може позначатися як $level$.
		\item[$\bullet$] Висотою дерева $d(\mathbb{T})$ називається найдовший простий шлях від кореня до листка.
	\end{enumerate}
	
	\hspace{0.8cm}Як $I={0,1...n-1}$ позначемо скінченну множину індексів з потужністю $|I|=n$. В майбутньому, в ролі $I$ використовуватимемо індекси базових функцій, отриманих для дискретизації з методу граничних елементів.
	\begin{Def}
	 {\bf (Кластерне дерево)} Дерево $\mathbb{T}_{I}$ називається кластерним деревом над множиною індексів $I$ з $root(\mathbb{T}_{I})=I$, якщо наступні умови виконуються:
	\begin{enumerate}
		\item[-] $I \in V$ є коренем $\mathbb{T}_{I}$ i $\forall v \in V,v\not=\O \Rightarrow v\subseteq I$.
		\item[-] Якщо $v\in V$ не є листком ($S(v)\not=\O$), то він рівний об'єднанню своїх синів, тобто $v=\bigcup_{w\in S(v)}w$.
	\end{enumerate}
	\end{Def}
	\par $v\in V$ називають кластером.
	
	\section{Означення блочного кластерного дерева}
	\hspace{0,8cm} Блочне кластирне дерево - це кластерне дерево над множиною індексів $I\times I$ замість $I$. В загальному, для неквадратних матриць, що належать до $\mathbb{R}^{I\times J}$, потрібно два різні кластерні дерева $\mathbb{T}_{I}$ та $\mathbb{T}_{J}$, тому ми розглядаємо інше кластерне дерево $\mathbb{T}_{J}$, яке базується на множині індексів $J$ потужності $|J|=m$. 
	\begin{Def}
	  Нехай $\mathbb{T}_{I}$ і $\mathbb{T}_{J}$ - кластерні дерева над множинами індексів $I$ та $J$ відповідно. Кластерне дерево $\mathbb{T}_{I\times J}=\mathbb{T}_{\mathbb{T}_{I}\times \mathbb{T}_{J}}=(V,E)$ називається блочним кластерним деревом над добутком множини індексів $I\times J$, якщо $\forall v\in V$ виконуються наступні умови:
	\begin{enumerate}
		\item[-] $\mathbb{T}^{(0)}_{I\times J}=I\times J$
		\item[-] Якщо $v\in \mathbb{T}^{(l)}_{I\times J}$, то існують $\tau \in \mathbb{T}^{(l)}_I$ i $\sigma \in \mathbb{T}^{(l)}_J$ такі, що $v=\tau \times \sigma$.
		\item[-] Для синів $v=\tau \times \sigma$, де  $\tau \in \mathbb{T}_I$ i $\sigma \in \mathbb{T}_J$ виконується
		\newline
		S(v)=$\begin{cases}
		$\O,$\text{якщо $S(\tau)=\O$ або $S(\sigma)=\O$}\\
		$$\{\tau^{\prime}\times\sigma^{\prime} : \tau^{\prime} \in S(\tau),\sigma^{\prime} \in S(\sigma)\}$,$\text{інакше}
		\end{cases}$
	\end{enumerate}
	\end{Def}
	\begin{Def}
		Блочне кластерне дерево $\mathbb{T}_{I\times J}$  для $\mathbb{T}_I$ та $\mathbb{T}_J$ називається однорідним, якщо 
		\begin{equation}
			\mbox{level}(t\times s) = \mbox{level}(t) = \mbox{level}(s)
		\end{equation}
		для всіх $t\times s\in \mathbb{T}_{I\times J}$.
	\end{Def}
	\newtheorem{Th}{Теорема}[chapter]
	
	\par Властивості блочного кластирного дерева $\mathbb{T}_{I\times J}$:
	\begin{itemize}
		\item Якщо обоє кластерні дерева $\mathbb{T}_I$ i  $\mathbb{T}_J$ є бінарними деревами, то отримане блочне кластерне дерево є quad-деревом, тобто кожний внутрішній вузол має точно чотири нащадки.
		\item $|\mathcal{L}(\mathbb{T}_{I\times J})|\le |\mathcal{L}(\mathbb{T}_I)|\cdot |\mathcal{L}(\mathbb{T}_J)|$
		\item $|\mathbb{T}_{I\times J}^{(l)}|\le |\mathbb{T}_I^{(l)}|\cdot |\mathbb{T}_J^{(l)}|$
		\item $d(\mathbb{T}_{I\times J})=min\{d(\mathbb{T}_I),d(\mathbb{T}_J)\}$
		\item Якщо $\mathbb{T}_{I\times J}$ - однорідне 
		$$S(t\times s) \not=\O\Rrightarrow S(t\times s) =\{t'\times s' : t' \in S(t),s' \in S(s)\} $$
	\end{itemize}
	
	\par Кількість можливих блоків $t\times s$ з вузлами $t,s$, що належать дереву $\mathbb{T}_I$ становить $(\#\mathbb{T}_I)^2=(2n-1)^2=\mathcal{O}(n^2)$. Оскільки ми не можемо тестувати всі можливі комбінації, нашою метою є зменшення квадратичної збіжності для збірки матриці. Можливим варіантом є тестування блоків рівень за рівнем починаючи від кореня $I$ дерева $\mathbb{T}_I$ і в подальшому заглиблюючись в дерево. Блоки, що тестуються, зберігають в блочному кластерному дереві $\mathbb{T}_{I\times I}$, листки якого утворюють поділ множини індексів $I\times I$. \par Алгоритм побудови блочного кластерного дерева (викликати з параметрами\newline BuildBlockClusterTree($I,I$)):
	\begin{algorithm}
	\caption{Побудова блочного кластерного дерева $\mathbb{T}_{I\times I}$}
	\begin{algorithmic}
	\STATE {\bf procedure} BuildBlockClusterTree(cluster t,s)
	\IF{$(t,s)$ is admissible}
	\STATE $S(t\times s):=\O$;
	\ELSE
	\STATE $S(t\times s):=\{t'\times s'|t'\in S(t)$ and $s'\in S(s)\}$;
	\FOR {$t'\in S(t)$ and $s'\in S(s)$}
	\STATE BuildBlockClusterTree($t',s'$);
	\ENDFOR
	\ENDIF
	\end{algorithmic}

	\end{algorithm}
	\newpage
	\section{Умова допустимості}
	\hspace{0.8cm} Під час побудови блочного кластерного дерева $\mathbb{T}_{I\times J}$ потрібна допоміжна умова, яка перевіряє чи блок $b=\tau\times\sigma\in \mathbb{T}_{I\times J}$ є відповідного розміру і в особливості чи він може бути наближений розрідженою матрицею. Це робиться за допомогою умови допустимості, яка в певному сенсі залежить від геометрії основної проблеми. Умова допустимості певним чином збалансовує точність апроксимації та вимоги до пам'яті $\mathcal{H}$-матриць.
	\begin{Def}
	Умова допустимості є булівською функцією 
	$$Adm:\mathbb{T}_{I\times J}\rightarrow\{true,false\}$$
	для якої виконується умова
	$$Adm(b)\Rightarrow Adm(b'),\quad\text{для всіх синів } b'\subseteq b\in \mathbb{T}_{I\times J} $$
	і властивість\newline 
	\hspace{2cm}$$Adm(b)=true, \quad\text{для всіх листків } b\in \mathbb{T}_{I\times J}$$
	\end{Def}
	\begin{Def}
		Поділ $\mathcal{P}$ називається допустимим ($\mathcal{P}_{Adm}$), якщо всі $b=(\tau\times\sigma)\in \mathcal{P}$ є допустимими.
	\end{Def}
	\hspace{0.8cm} Стандартна умова допустимості була вперше описана в класичній побудові $\mathcal{H}$-матриць, де вона застосовується для розподілу, здебільшого для проблем, що вирішуються за допомогою методу граничних елементів.
	\begin{Def}
	Нехай $\eta>0$ - фіксований параметр. Кажуть, що блок $b=\tau\times\sigma$ задовольняє стандартину умову допустимості, якщо 
	$$Adm_\eta(b)=true\Leftrightarrow min(diam(\Omega_{\tau}),diam(\Omega_{\sigma}))\le \eta\cdot dist(\Omega_{\tau},\Omega_{\sigma})$$
	де $\Omega_{\tau}$ i $\Omega_{\sigma}$ визначаються як
	$$\Omega_{\tau}:=\bigcup_{i\in \tau}supp(\varphi_i)$$
	$$\Omega_{\sigma}:=\bigcup_{i\in \sigma}supp(\varphi_i)$$
	\end{Def}
	\par В попередніх означеннях "diam" i "dist" позначають Евклідовий діаметр і відстань між $\Omega_{\tau}$ та $\Omega_{\sigma}$. Вони визначаються наступним чином:
	$$diam(\Omega_{\tau}):=\max_{x_i,x_j\in\Omega_{\tau}}||x_i-x_j||$$
	$$dist(\Omega_{\tau},\Omega_{\sigma}):=\min_{x_i\in\Omega_{\tau},x_j\in\Omega_{\sigma}}||x_i-x_j||$$
	\par Якщо в означені 4.3 замінити "min" на "max", то отримуємо сильну умову допустимості:
	$$Adm_\eta(b)=true\Leftrightarrow max(diam(\Omega_{\tau}),diam(\Omega_{\sigma}))\le \eta\cdot dist(\Omega_{\tau},\Omega_{\sigma})$$
	\begin{Def}
		Блочне кластерне дерево $\mathbb{T}_{I\times J}$  для $\mathbb{T}_I$ та $\mathbb{T}_J$ називається допустимим у відповідності до умови допустимості, якщо 
		\begin{equation}
			t\times s \mbox{ є допустимим    або    } sons(t)=\O\mbox{   або   }sons(s)=\O
		\end{equation}
		виконується для всіх листків $t\times s\in\mathcal{L}(\mathbb{T}_{I\times J})$.
	\end{Def}

	\section{Означення $\mathcal{H}$-матриці}
	\hspace{0.8cm} На допустимих блоках апроксимуємо за допомогою структури rkmatrix. На недопустимих листках використовуємо структуру fullmatrix.
	\par $n_{min}$ - розмірність найменшого листка.
	\begin{Def}
	Нехай $M\in\mathbb{R}^{I\times J}$ - матриця над множиною індексів $I\times J$. Підматриця $(M_{i,j})_{(i,j)\in I'\times J'}$ для підмножини $I'\times J'$ множини $I\times J$ позначається як $M|_{I'\times J'}$.
	\end{Def}
	\begin{Def}
	($\mathcal{H}$-матриця) Нехай $k,n_{min}\in \mathbb{N}_0$. Множина $\mathcal{H}$-матриць, що базується на допустимому поділі $\mathcal{P}_{Adm}$ над блочним кластерним деревом $\mathbb{T}:=\mathbb{T}_{I\times J}$ визначається як 
	$$\mathcal{H}(\mathbb{T},k):=\{M\in\mathbb{R}^{I\times J}|\forall\tau\times\sigma\in\mathcal{P}_{Adm}:rank(M|_{\tau\times\sigma})\le k \text{ або } \min(|\tau|,|\sigma|)\le n_{min} \}$$ 
	\end{Def}
	\par Спрощене означення $\mathcal{H}$-матриці виглядає наступним чином 
	\begin{Def}
	Нехай $\mathbb{T}_{I\times I}$ - блочне кластерне дерево над множиною індексів $I$. Означаємо множину $\mathcal{H}$-матриць як
	$$\mathcal{H}(\mathbb{T}_{I\times I},k):=\{M\in\mathbb{R}^{I\times I}|rank(M|_{t\times s})\le k \text{ для всіх допустимих листків } t\times s \text{ дерева } \mathbb{T}_{I\times I} \}$$
	\end{Def}
	\chapter{3. Розв'язання модельного інтегрального рівняння.}
	\section{Модельна задача}
	\hspace{0.8cm}Розглянемо застосування {$\mathcal{H}$}-матриць на прикладі одновимірного інтегрального рівняння Фредгольма першого роду. Нехай задано функцію $F:[0,1]\rightarrow \mathbb{R}$. Шукаємо функцію $u:[0,1]\rightarrow \mathbb{R}$, яка задовільняє наступне інтегральне рівняння: $$\int_{0}^{1}\ln|x-y|u(y)dy=F(x), x\in[0,1]$$
	де $g(x,y)=\ln|x-y|$ називається ядром інтегрального рівняння і має невизначеність на діагоналі $x=y$.
	\par Використовуючи метод Гальоркіна,проектуємо дане рівнання на n-вимірний простір $V_n=span\{\varphi_0,\dots,\varphi_{n-1}\}$
	i отримуємо:
	$$\int_{0}^{1}\int_{0}^{1}\varphi_i(x)\ln|x-y|u(y)dydx=\int_{0}^{1}\varphi_i(x)F(x)dx$$
	$0\le i<n$
	\par Потрібно знайти $u_n$ в просторі $V_n$:
	$$u_n=\sum_{j=0}^{n-1}u_j\varphi_j$$
	таке, що вектор коефіцієнтів $u$ є розв'язком лінійної системи $$Gu=f$$
	$$G_{ij}=\int_{0}^{1}\int_{0}^{1}\varphi_i(x)\ln|x-y|\varphi_j(y)dydx$$
	$$f_i=\int_{0}^{1}\varphi_i(x)F(x)dx$$
	 В цьому прикладі визначаємо базисні функції як
	\newline 
	\begin{equation*}
	\varphi_i(x)=\begin{cases}
			1,\quad\text{якщо $\frac{i}{n}\le x< \frac{i+1}{n}$}\\
			0,\quad\text{інакше}
				\end{cases}
	\end{equation*}
	\newline
	які в загальному матимуть вигляд 
	\newline
		\includegraphics{1_1}
	\par Матриця G є щільною, тобто всі елементи не є нулями. Потрібно знайти наближену матрицю \~G, яка може бути збереженою в розрідженому форматі. Для того, щоб це досягти потрібно замінити ядро $g(x,y)=\ln|x-y|$ на розкладене ядро $$\tilde{g}(x,y)=\sum_{v=0}^{k-1}g_v(x)h_v(y)$$
	\par Таким чином, інтегрування за змінною x буде відкремленим від інтегрування за змінною y. Проте, ядро  $g(x,y)=\ln|x-y|$ не можна наблизити розкладеним ядром на цілій області $[0,1]\times[0,1]$ (хіба що при великому k). Змість цього, ми будуємо локальні наближення на підобластях $[0,1]\times[0,1]$, де $g$ є гладкою.
	\section{Розклад ядра в ряд Тейлора}
	\hspace{0.8cm}Нехай $\tau:=[a,b]$, $\sigma:=[c,d]$, $\tau\times\sigma\subset[0,1]\times[0,1]$ буде підобластю з властивістю $b<c$ і інтервали є роз'єднаними, тобто $$\tau\cap\sigma=\O$$
	Тоді ядро є визначеним на $\tau\times\sigma$. $x_0:=(a+b)/2$
	\newtheorem{Lem}{Лема}[chapter]
	\begin{Lem}
		{\bf (Похідні $\ln|x-y|$)} Похідні $g(x,y)=\ln|x-y|$ для $x\not=y$ i $v\in \mathbb{N}$ мають вигляд
		$$\partial^v_xg(x,y)=(-1)^{v-1}(v-1)!(x-y)^{-v}$$
		$$\partial^v_yg(x,y)=(v-1)!(x-y)^{-v}$$
	\end{Lem}
	\begin{Lem}
	{\bf (Розклад Тейлора для $\ln|x-y|$)} Для будь-якого $k\in \mathbb{N}$ функція 
	$$\tilde{g}(x,y)=\sum_{v=0}^{k-1}\frac{1}{v!}\partial^v_xg(x_0,y)(x-x_0)^v$$
	наближає ядро $g(x,y)=\ln|x-y|$ з похибкою
	$$|g(x,y)-\tilde{g}(x,y)|\le(1+\frac{|x_0-a|}{|c-b|})(1+\frac{|c-b|}{|x_0-a|})^{-k}$$
	\end{Lem}
	 Доведення. Нехай $x\in [a,b],a<b$ i $y\in [c,d]$. В радіусі збіжностi ряд Тейлора для ядра $g(x,y)$ в точці $x_0$ задовільняє $$g(x,y)=\sum_{v=0}^{\infty}\frac{1}{v!}\partial^v_xg(x_0,y)(x-x_0)^v$$
	Залишок $g(x,y)-\tilde{g}(x,y)=\sum_{v=k}^{\infty}\frac{1}{v!}\partial^v_xg(x_0,y)(x-x_0)^v$ може бути оцінений як:
	$$|\sum_{v=k}^{\infty}\frac{1}{v!}\partial^v_xg(x_0,y)(x-x_0)^v|= |\sum_{v=k}^{\infty}(-1)^{v-1}\frac{(v-1)!}{v!}\genfrac{(}{)}{1pt}{0}{x-x_0}{x_0-y}^v|$$
	$$\le \sum_{v=k}^{\infty}|\frac{x-x_0}{x_0-y}|^v\le\sum_{v=k}^{\infty}\genfrac{(}{)}{1pt}{0}{|x_0-a|}{|x_0-a|+|c-b|}^v $$
	$$=(1+\frac{|x_0-a|}{|c-b|})(1+\frac{|c-b|}{|x_0-a|})^{-k}$$
	\newline Радіус збіжності покриває весь інтервал $[a,b]$. 
	\newline
	\par Якщо $c\rightarrow b$, то оцінка залишку прямує до нескінченості і наближення буде як завгодно поганим. Проте, якщо замінити умову $b<c$ (диз'юнкція інтервалів) сильнішою умовою допустимості
	$$diam(\tau)\le dist(\tau,\sigma)$$
	то похибка апроксимації може бути оцінена як 
	$$|g(x,y)-\tilde{g}(x,y)|\le\frac{3}{2}(1+\frac{2}{1})^{-k}=\frac{3}{2}3^{-k}$$
	\par Це означає, що ми отримуємо рівномірну оцінку для похибки наближення незалежно від інтервалів, якщо умова допустимості виконується. Похибка зростає експоненціально в залежності від порядку $k$.
	\section{Наближення низького рангу блоків матриці}
	\par Множина індексів $I=\{0,1,\dots,n-1\}$ містить індекси базових функцій $\varphi_i$, які використовуються в дискритизації Галеркіна. Фіксуємо дві підмножини $t$ і $s$ множини індексів $I$ та визначимо відповідні області:
	$$\tau=\bigcup_{i\in t}supp(\varphi_i)$$
	$$\sigma=\bigcup_{i\in s}supp(\varphi_i)$$
	\par Якщо $\tau\times\sigma$ задовільняє умову допустимості, то ми можемо наблизити ядро $g$ в цій підобласті рядом Тейлора $\tilde{g}$ і замінити елементи матриці
	$$G_{ij}=\int_{0}^{1}\int_{0}^{1}\varphi_i(x)g(x,y)\varphi_j(y)dydx$$
	використовуючи вироджене ядро $\tilde{g}=\sum_{v=0}^{k-1}g_v(x)h_v(y)$ для індексів $(i,j)\in t\times s$:
	$$\tilde{G}_{ij}=\int_{0}^{1}\int_{0}^{1}\varphi_i(x)\tilde{g}(x,y)\varphi_j(y)dydx$$
	Розділяємо подвійний інтеграл на два звичайні
	$$\tilde{G}_{ij}=\int_{0}^{1}\int_{0}^{1}\varphi_i(x)\sum_{v=0}^{k-1}g_v(x)h_v(y)\varphi_j(y)dydx $$
	$$=\sum_{v=0}^{k-1}(\int_{0}^{1}\varphi_i(x)g_v(x)dx)(\int_{0}^{1}\varphi_j(y)h_v(y)dy)$$
	\par Підматриця $G|_{t\times s}$ може бути записана в факторизованій формі
	$$G|_{t\times s}=AB^\top,\quad A\in\mathbb{R}^{t\times\{0,\dots,k-1\}},\quad B\in\mathbb{R}^{s\times\{0,\dots,k-1\}}$$
	де елементами матиць $A$ i $B$  
	$$A_{iv}:=\int_{0}^{1}\varphi_i(x)g_v(x)dx, \quad B_{jv}:=\int_{0}^{1}\varphi_j(y)h_v(y)dy$$
	\includegraphics{1_6}
	\par Матриця $AB^\top$ має найбільший ранг $k$ в незалежності від потужності $s$ i $t$. Похибка наближення блоку матриці оцінена в наступній лемі.
	\begin{Lem}
	Поелементна похибка для елементів матриці $G_{ij}$ апроксимується ядром $\tilde{g}$ в допустимих блоках $t\times s$ ($g$ в інших блоках) обмежена наступним чином
	$$|G_{ij}-\tilde{G}_{ij}|\le \frac{3}{2}n^{-2}3^{-k}$$
	\end{Lem}
	{\bf Доведення.} $\quad|G_{ij}-\tilde{G}_{ij}|=|\int_{0}^{1}\int_{0}^{1}\varphi_i(x)(g(x,y)-\tilde{g}(x,y)\varphi_j(y)dydx|$
	$$\le \int_{0}^{1}\int_{0}^{1}|\varphi_i(x)|\frac{3}{2}3^{-k}|\varphi_j(y)|dydx$$
	$$=\frac{3}{2}3^{-k}\int_{0}^{1}\varphi_i(x)dx\int_{0}^{1}\varphi_j(y)dy$$
	$$= \frac{3}{2}n^{-2}3^{-k} \quad\blacksquare$$ 
	\par Припустимо, що ми поділили множину індексів $I\times I$ над матрицею $G$ на допустимі блоки, де застосовується апроксимація низького рангу, і недопустимі блоки, де використовуємо елементи матриці $G$.
	$$I\times I=\bigcup_{v=1,\dots,b}t_v\times s_v$$
	\par Глобальну похибку наближення оцінюємо, застосовуючи норму Фробеніуса 
	$$\|M\|^2_F:=\sum M_{ij}^2$$
	\begin{Lem}
	Похибка наближення $\|G-\tilde{G}\|_F$ для матриці $\tilde{G}$, побудованої за допомогою ядра $\tilde{g}$ в допустимих блоках $t_v\times s_v$ та з допомогою $g$ на недопустимих блоках, обмежена наступним чином
	$$\|G-\tilde{G}\|_F\le \frac{3}{2}n^{-1}3^{-k}$$
	\end{Lem}
	\par Постає питання, як поділити множину індексів $I\times I$ на допустимі та недопустимі блоки. Тривіальним поділом був би $\mathcal{P}:=\{(i,j)|i\in I,j\in I\}$, де є тільки блоки розмірності $1\times 1$, ранг рівний 1. В цьому випадку, матриця $\tilde{G}$ є ідентичною до $G$, але в цьому випадку ми не апроксимуємо матрицю у великих підблоках матрицями низького рангу. 
	\section{Одновимірний випадок побудови блочного кластерного дерева}
	\subsection{Приклад побудови кластерного дерева}
	\par В одновимірному випадку кластерне деревр - збалансоване бінарне дерево.
	\par {\bf Приклад.} Одновимірний випадок.\newline
	Як корінь дерева $\mathbb{T}_{I}$ беремо множину індексів $I_0^{(0)}=\{0,...,n-1\}$. Для легкості презентації припустимо, що кількість базисних функцій $n$ є степенем 2:
	$$n=2^p$$ 
	\par Розглядаємо випадок, коли $p=3$.Починаючи з кореня, де тільки один кластер, це дерево конструюється шляхом поділу кожної множини індексів $I_i^{(j)}$ на два нащадки $I_{2i}^{(j+1)}$ і $I_{2i+1}^{(j+1)}$ при $0\le i,j\le p$. Нарешті на рівні $p$ всі кластери (вузли) є листками, наприклад $\mathcal{L}(\mathbb{T})=\{I_i^{(3)}\}_{i=0}^7$. Кожен вузол (окрім листків) отриманого дерева матиме рівно два нащадки:
	\par Два нащадки $I_0^{(0)}$: $I_0^{(1)}=\{0,...,\frac{n}{2}-1\}$  i  $I_1^{(1)}=\{\frac{n}{2},...,n-1\}$. 
	\par Два нащадки $I_0^{(1)}$: $I_0^{(2)}=\{0,...,\frac{n}{4}-1\}$  i  $I_1^{(2)}=\{\frac{n}{4},...,\frac{n}{2}-1\}$.
	\par Два нащадки $I_1^{(1)}$: $I_2^{(2)}=\{\frac{n}{2},...,\frac{3n}{4}-1\}$  i  $I_3^{(2)}=\{\frac{3n}{4},...,n-1\}$.  
	\newline
	\par З практичної точки зору, $\mathbb{T}_{I}$ зазвичай є бінарним деревом. Висота бінарного дерева $\approx\log(n)$, а отже складність побудови cluster tree - $O(n\log(n))$.
	\begin{figure}[bh]{
			\includegraphics[scale=0.5]{1_0}
		}
		\caption{Кластерне дерево при p=3.}
	\end{figure}	
	
	\subsection{Умова допустимості}
	\par В подальшому для одновимірної проблеми ми будемо використовувати стандартну умову допустимості в такому вигляді
	\newline
	$$\includegraphics{1_2}$$
	$$diam(\tau)\le dist(\tau,\sigma)$$
	\section{Приклад побудови блочного кластерного дерева.}
	\includegraphics[scale=0.45]{1_3}
	\par Кроки побудови блочного кластерного дерева при p=3:
	\begin{enumerate}
		\item Коренем дерева є блок $\{0,1,2,3,4,5,6,7\}\times\{0,1,2,3,4,5,6,7\}$, який не задовільняє умову допустимості, тому що відповідною областю до множини індексів $\{0,1,2,3,4,5,6,7\}$ є інтервал $[0,1]$ i $$diam([0,1])=1\le 0=dist([0,1],[0,1])$$
		\item Чотирьма нащадками кореня в дереві $\mathbb{T}_{I\times I}$ є
		$$\{0,1,2,3\}\times\{0,1,2,3\},\quad\{0,1,2,3\}\times\{4,5,6,7\},$$
		$$\{4,5,6,7\}\times\{0,1,2,3\},\quad\{4,5,6,7\}\times\{4,5,6,7\}.$$
		\par Жоден з них не задовільняє умову допустимості.
		\item Після подальшого поділу, отримуємо такі блоки:
		$$\{0,1\}\times\{0,1\},\quad\{0,1\}\times\{2,3\},\quad\{0,1\}\times\{4,5\},\quad\{0,1\}\times\{6,7\},$$
		$$\{2,3\}\times\{0,1\},\quad\{2,3\}\times\{2,3\},\quad\{2,3\}\times\{4,5\},\quad\{2,3\}\times\{6,7\},$$
		$$\{4,5\}\times\{0,1\},\quad\{4,5\}\times\{2,3\},\quad\{4,5\}\times\{4,5\},\quad\{4,5\}\times\{6,7\},$$
		$$\{6,7\}\times\{0,1\},\quad\{6,7\}\times\{2,3\},\quad\{6,7\}\times\{4,5\},\quad\{6,7\}\times\{6,7\}.$$
		Деякі з циз вузлів задовольняють умову допустимості, наприклад вузол $\{0,1\}\times\{4,5\}$, тому що відповідною областю є $[0,\frac{1}{4}]\times [\frac{1}{2},\frac{3}{4}]$:
		$$diam([0,\frac{1}{4}])=\frac{1}{4}=dist([0,\frac{1}{4}],[\frac{1}{2},\frac{3}{4}])$$
		Вузли на діагоналі не задовольняють умову допустимості (відстань від відповідної області до себе самої рівна нулю) і деякі вузли не на діагоналі (наприклад $\{0,1\}\times \{2,3\}$) не задовольняють умову допустимості.
		\item Нащадками цих вузлів є $\{(i,j)\}$ для індексів $i,j$. 
		Кінцева структура буде:
		\includegraphics[scale=0.5]{1_4}
	\end{enumerate}
	\par Аналогічно можна побудувати блочного кластерного дерева для $p=4$ чи $p=5$.
	\section{Побудова матриці}
	\hspace{0.8cm} Ієрархічна матриця розкладається на допустимі і недопустимі листки дерева $\mathbb{T}_{I\times I}$. Для них створені два підкласи, опрацювання яких різниться.
	\subsection{Недопустимі листки}
	\hspace{0.8cm} В недопустимих, але малих блоках $t\times s\subset I\times I$ обчислюємо елементи матриці $(i,j)$ за формулою
	$$\tilde{G_{ij}}:=\int_{0}^{1}\int_{0}^{1}\varphi_i(x)\ln|x-y|\varphi_j(y)dydx$$$$=\int_{i/n}^{(i+1)/n}\int_{j/n}^{(j+1)/n}\ln|x-y|dydx$$
	\begin{Def}
		(репрезентація fullmatrix) Кажуть, що матриця $M$ розмірності $n\times m$ зберігається у вигляді fullmatrix, якщо її елементи $M_{ij}$ зберігаються як дійсні числа у масиві довжиною $mn$ в стовпцевому порядку
		$$M_{11},\dots,M_{n1},M_{12},\dots,M_{n2},\dots,M_{1m},\dots,M_{nm}$$
	\end{Def}
	\par Порядок елементів матриці в репрезентації fullmatrix є таким самим, як і в стандартних пакетах лінійної алгебри (MATLAB,BLAS,LAPACK тощо).
	\par Реалізація на мові програмування $Kotlin$:
	\begin{verbatim}
	data class Fullmatrix(
						  var rows:Int=0,
						  var cols:Int=0,
						  var e:Array<DoubleArray> = Array(rows){DoubleArray(cols)})
	\end{verbatim}
	\subsection{Допустимі листки}
	\hspace{0.8cm} В допустимих блоках $t\times s\subset I\times I$ з відповідними областями $[a,b]\times [c,d]$ i $x_0:=(a+b)/2$ обчислюємо відповідну матрицю у факторизованій формі
	$$\tilde{G}|_{t\times s}:=AB^\top$$
	$$A_{iv}:=\int_{i/n}^{(i+1)/n}(x-x_0)^vdx$$
	\begin{equation*}
		B_{jv}:=\begin{cases}
					(-1)^{v+1}v^{-1}\int_{j/n}^{(j+1)/n}(x_0-y)^{-v}dy,\quad\text{якщо $v>0$}\\
					\int_{j/n}^{(j+1)/n}\ln|x_0-y|dy,\quad\text{якщо $v=0$}
				\end{cases}
	\end{equation*}
	\par Підходящою репрезентацією для відповідної матриці $\tilde{G}|_{t\times s}$ є формат rkmatrix наведений нище.
	\begin{Def}
		(репрезентація rkmatrix)  Кажуть, що матриця $M$ розмірності $n\times m$ найбільшого рангу $k$ зберігається у вигляді rkmatrix, якщо вона зберігається у факторизованій формі $M=AB^\top$, де обидві матриці $A\in\mathbb{R}^{n\times k}$ i $B\in \mathbb{R}^{m\times k}$ зберігаються як масиви (в стовпцевому порядку).
	\end{Def}
	\par Реалізація на мові програмування $Kotlin$:
	\begin{verbatim}
	data class Rkmatrix(
	    val k:Int,val rows:Int,val cols:Int,
	    var a:Array<DoubleArray> = Array(rows){
	       DoubleArray(k)
	    },
	    var b:Array<DoubleArray> = Array(cols){
	       DoubleArray(k)
	})
	\end{verbatim}
	\subsection{Репрезентація ієрархічної матриці}
	\begin{Def}
		(репрезентація $\mathcal{H}$-матриці)  Нехай $\mathbb{T}_{I\times I}$ - блочне кластерне дерево над множиною індексів $I$. Кажуть, що матриця $M\in\mathcal{H}(\mathbb{T}_{I\times I},k)$ зберігається в $\mathcal{H}$-matrix репрезентації, якщо підматриці, що відповідають недопустимим листкам, зберігаються у вигляді fullmatrix, а ті, що відповідають допустимим листкам - у вигляді rkmatrix. 
	\end{Def}
	\par Однією можливою реалізацією $\mathcal{H}$-matrix репрезентації є зберігання допустимих і недопустимих блоків матриці в списку. Збірка і множення матриці на вектор робиться для кожного блоку окремо. Проте, ми використаємо іншу реалізацію, яка базується на структурі блочного кластерного дерева $\mathbb{T}_{I\times I}$ (не тільки на листках) і таким чином зберігає матрицю у більш структурованому вигляді.
	\par Кожен блок $t\times s$ в дереві $\mathbb{T}_{I\times I}$ може бути 
	\begin{itemize}
		\item листком - тоді відповідний блок матриці представлений у вигляді fullmatrix або rkmatrix.
		\item не листком - тоді блок $t\times s$ розкладають на його синів $t'\times s'$ з $t'\in S(t)$ та $s' \in S(s)$. Це означає матриця, що відповідає блоку $t\times s$ -- $supermatrix$ і вона складається з підматриць, що відповідають блоку $t'\times s'$.
	\end{itemize} 
	\par Реалізація на мові програмування $Kotlin$:
	\begin{verbatim}
	data class Supermatrix(var rows:Int = 0, var cols:Int = 0,
	    var blockrows:Int=0, var blockcols:Int =0,
	    var rkmatrix:Rkmatrix?=null,
	    var fullmatrix: Fullmatrix?=null, 
	    var supermatrix: Array<Array<Supermatrix>>?=null)
	
	\end{verbatim}

	$$M\in\mathbb{R}^{rows\times cols}$$
	\par Матриця може бути 
	\begin{itemize}
		\item rkmatrix - тоді 
		$$r\not=null,\quad
		f=null,\quad
		s=null$$
		Матриця $r$ - це репрезентація rkmatrix матриці $M$.
		\item fullmatrix - тоді  
		$$r=null,\quad
		f\not=null,\quad
		s=null$$
		Матриця $f$ - це репрезентація fullmatrix матриці $M$.
		\item supermatrix - тоді
		$$r=null,\quad
		f=null,\quad
		s\not=null$$
		Матриця $s$ містить вказівники на підматриці $M_{i,j}$:
		\[
			\begin{pmatrix}
				M_{1,1} & \dots & M_{1,blockcols}\\
				\vdots & \ddots & \vdots \\
				M_{blockrows,1} &\dots  & M_{blockrows,blockcols}
			\end{pmatrix}
		\]
		в порядку 
		$$M_{1,1},\dots,M_{blockrows,1},M_{1,2},\dots,M_{blockrows,2},\dots,M_{1,blockcols},\dots,M_{blockrows,blockcols}$$
	\end{itemize}
	\par Реалізацією $\mathcal{H}$-матриці є дерево з вузлами, що реалізовані як $supermatrix$. На додаток, структура таж сама, що і в блочному кластерному дереві $\mathbb{T}_{I\times I}$ (нащадки $\equiv$ підматриці) і підматриці, що відповідають допустимим та недопустимим листкам, зберігаються в форматі rkmatrix i fullmatrix.
	\section{Розпис інтегралів}
	\hspace{0.8cm}Для заповнення $\mathcal{H}-$матриці потрібно обчислити інтеграли. Для цього будемо застосовувати наступні формули, отримані за правилом інтегрування чистинами:
	
	\begin{equation}
		\int \log(x) dx = x\log(x)-\int 1 dx = x\log(x)-x\\
	\end{equation}
	$$\int x\log(x)dx=\int\log(x)d\Big(\frac{x^2}{2}\Big)=\frac{x^2\log(x)}{2}-\int \frac{x}{2}dx=\frac{x^2\log(x)}{2}-\frac{x^2}{4}=\frac{1}{4}x^2(2\log(x)-1)$$
	\begin{equation}
	\int x\log(x)dx=\frac{1}{4}x^2\big(2\log(x)-1\big)
	\end{equation}
	\subsection{Допустимі блоки}
	 Для заповнення матриці $A$:
	$$\int_{a}^{b}(x-x_0)^vdx=\frac{(x-x_0)^{v+1}}{v+1}\Bigg|_a^b$$
	 Для заповнення матриці $B$ при $v>0$:
	$$\int_{a}^{b}(x_0-y)^{-v}dy=-\frac{(x_0-y)^{-v+1}}{-v+1}\Bigg|_a^b$$
	 У випадку $v\le0$ розглядаємо два випадки для того, щоб розкрити модуль
	\begin{equation*}
	\int_a^b\log|x_0-y|dy =\begin{cases}
	\int_{a}^{b}\log(x_0-y)dy,\quad\text{якщо $y\le x_0$}\\
	\int_{a}^{b}\log(y-x_0)dy,\quad\text{якщо $y>x_0$}
	\end{cases}
	\end{equation*}
	До отриманих інтегралів застосовуємо (3.1).
	\subsection{Недопустимі блоки}
	Для розв'язання інтегралів можемо розглянути два методи.
		\begin{itemize}
			\item З огляду на розташування інтервалів $[a,b]$ i $[c,d]$ розкриваємо інтеграли. 
		\begin{itemize}
			\item[$\bullet$] a = b
			
			$$\int_{a}^{b}\int_{a}^{b}\log\big| x-y \big|dydx=\int_{a}^{b}\Bigg\{\int_{a}^{x}log(x-y)dy+\int_{x}^{b}log(y-x)dy\Bigg\}dx =$$ $$\int_{a}^{b}\Bigg\{\big(-(x-y)\log(x-y)+(x-y)\big)\Big|_{y=a}^{y=x}+\big((y-x)\log(y-x)-(y-x)\big)\Big|_{y=x}^{y=b} \Bigg\}dx = $$
			$$\int_{a}^{b}\Bigg\{(x-a)\log(x-a)-x+a+(b-x)\log(b-x)-b+x\Bigg\}dx=$$
			$$\int_{a}^{b}\Bigg\{(x-a)\log(x-a)+(b-x)\log(b-x)+a-b\Bigg\}dx=$$
			$$\Bigg(\frac{1}{4}(x-a)^2\big(2\log(x-a)-1\big)-\frac{1}{4}(b-x)^2\big(2\log(b-x)-1\big)+ax-bx\Bigg)\Big|_{x=a}^{x=b}=$$
			$$\frac{1}{4}(b-a)^2\big(2\log(b-a)-1\big)+ab-b^2+\frac{1}{4}(b-a)^2\big(2\log(b-a)-1\big)-a^2+ab=$$
			$$\frac{1}{2}(b-a)^2\big(2\log(b-a)-1\big)-(b-a)^2=$$
			$$(b-a)^2\log(b-a)-\frac{3(b-a)^2}{2}$$
		
			\item[$\bullet$] a<c
			$$\int_{a}^{b}\int_{c}^{d}\log\big| x-y \big| dydx=\int_{a}^{b}\int_{c}^{d}\log(y-x)dydx=$$
			$$\int_{a}^{b}\Bigg\{\big((y-x)\log(y-x)-y+x\big)\Bigg|_{y=c}^{y=d}\Bigg\}dx=$$
			$$\int_{a}^{b}\Bigg\{(d-x)\log(d-x)-d+x-(c-x)\log(c-x)+c-x\Bigg\}dx=$$
			$$\int_{a}^{b}\Bigg\{(d-x)\log(d-x)-(c-x)\log(c-x)+c-d\Bigg\}dx=$$
			$$\Bigg(-\frac{1}{4}(d-x)^2\big(2\log(d-x)-1\big)+\frac{1}{4}(c-x)^2\big(2\log(c-x)-1\big)+cx-dx\Bigg)\Bigg|_{x=a}^{x=b}=$$
			$$-\frac{1}{4}(d-b)^2\big(2\log(d-b)-1\big)+\frac{1}{4}(c-b)^2\big(2\log(c-b)-1\big)+\frac{1}{4}(d-a)^2\big(2\log(d-a)-1\big)$$$$-\frac{1}{4}(c-a)^2\big(2\log(c-a)-1\big)+cb-db-ca+da$$
			\item[$\bullet$] a>c
			$$\int_{a}^{b}\int_{c}^{d}\log\big| x-y \big|dydx=\int_{a}^{b}\int_{c}^{d}\log(x-y)dydx=$$
			$$\int_{a}^{b}\Bigg\{\big(-(x-y)\log(x-y)+x-y\big)\Bigg|_{y=c}^{y=d}\Bigg\}dx=$$
			$$\int_{a}^{b}\Bigg\{-(x-d)\log(x-d)+(x-c)\log(x-c)+c-d\Bigg\}dx=$$
			$$\Bigg(-\frac{1}{4}(x-d)^2\big(2\log(x-d)-1\big)+\frac{1}{4}(x-c)^2\big(2\log(x-c)-1\big)+cx-dx\Bigg)\Bigg|_{x=a}^{x=b}=$$
			$$-\frac{1}{4}(b-d)^2\big(2\log(b-d)-1\big)+\frac{1}{4}(b-c)^2\big(2\log(b-c)-1\big)+\frac{1}{4}(a-d)^2\big(2\log(a-d)-1\big)$$$$-\frac{1}{4}(a-c)^2\big(2\log(a-c)-1\big)+cb-db-ca+da$$
		\end{itemize}
	\item[-] Застосовуємо формулу інтегрування частинами
		$$\int_{a}^{b}\int_{c}^{d}\log\big| x-y \big|dydx=\int_{a}^{b}\mathcal{F}(x)dx$$
		$$\int\log\big| y-x \big|dy = \big[u=y-x\rightarrow dy=du\big]=\int\log| u|du$$
		Застосовуємо інтегрування частинами $\int fg^\prime = fg-\int f^\prime g$, де $f=\log|u|$, $g^\prime =1$.
		$$\int\log| u|du = u\log|u|-\int 1du = u\log|u|-u = (y-x)\log\big|y-x\big|-y+x+C$$
		$$\mathcal{F}(x)=\Bigg(\left(y-x\right)\left(\log\left(\left|y-x\right|\right)-1\right)\Bigg)\Bigg|_{y=c}^{y=d}=\left(d-x\right)\left(\log\left|d-x\right|-1\right)+(x-c)\log|x-c|-d+c$$
		Аналогічно до виведення (3.2) можна розписати отримані інтеграли
		$$\int_{a}^{b}\mathcal{F}(x)dx = \int_{a}^{b}\Bigg\{\left(d-x\right)\left(\log\left|d-x\right|-1\right)+(x-c)\log|x-c|-d+c\Bigg\}dx =$$
		$$\Bigg(-\dfrac{\left(x-d\right)^2\left(2\ln\left(\left|x-d\right|\right)-1\right)}{4}+\dfrac{\left(x-c\right)^2\left(2\ln\left(\left|x-c\right|\right)-1\right)}{4}-dx+cx\Bigg)\Bigg|_{a}^{b}$$
		\end{itemize}
	\section{Метод спряжених градієнтів}
	\hspace{0.8cm} Метод спряжених градієнтів (conjugate gradient method) - це найпопулярніший ітеративний метод для розв'язування великих систем лінійних рівнянь. Такі ітеративні методи добре підходять, коли розглядають розріджені матриці. Метод спряжених градієнтів є ефективним для систем у вигляді $$Ax=b$$
	де $x$-невідомий вектор\\
	$b$ - відомий вектор\\
	$A$ - відома, квадратна, симетрична, додатньо визначена матриця.\par Ці системи виникають у багатьох задачах, таких як скінченна різниця і метод скінченних елементів для розв'язання диференціальних рівняння з частинними похідними.
	\par Цей метод випливає з того, що $x_{*}$(розв'язок системи) мінімізує єдиним чином квадратичну функцію
	$$f(x)=\frac{1}{2}x^\top Ax-x^\top b, x\in\mathbb{R}^n$$
	\par Метод спряжених градієнтів вимагає від матриці тільки можливості помножити її на вектор, що дає можливість застосовувати спеціальні формати зберігання матриці.
	\begin{algorithm}
	\caption{Алгоритм методу спряжених градієнтів}
	\begin{algorithmic}
		\STATE $r_0:=b-Ax$
		\STATE $p_0:=r_0$
		\STATE $k:=0$
		\WHILE {$true$}
			\STATE $\alpha_k:=\frac{r_k^{\intercal}r_k}{p_k^{\intercal}Ap_k}$
			\STATE $x_{k+1}:=x_k+\alpha_kp_k$
			\STATE $r_{k+1}:=r_k-\alpha_kAp_k$
			\IF {$r_{k+1}$ достатньо мале}
				\STATE вийти з циклу
			\ENDIF
			\STATE $\beta_k=\frac{r_{k+1}^{\intercal}r_{k+1}}{r_k^\intercal r_k}$
			\STATE $p_{k+1}:=r_{k+1}+\beta_kp_k$
			\STATE $k:=k+1$
		\ENDWHILE
		\STATE результатом є $x_{k+1}$
	\end{algorithmic}
	
	\end{algorithm}
	\section{Чисельні експерименти}
	\hspace{0.8cm}В усіх наведених експериментах, розглядаємо випадок $n_{min}=2k$.
	\subsection{Приклад 1}
	\hspace{0.8cm}Розглядаємо рівняння
	$$\int_{0}^{1}\log|x-y|u(y)dy = x\log|x|+(1-x)\log|1-x|-1$$
	Враховуючи $\frac{d(|x|)}{dx}=\frac{x}{|x|}$ і застосувавши формулу похідної від добутку, можемо показати що точний розв'язок $u^{*}(x)=1$:
	$$\int \log|x-y|dy=(y-x)\big(\log|y-x|-1\big)$$

	
	\begin{table}[hbt!]
		\centering 
		\begin{tabular}{c c c c c c } % centered columns (4 columns)
			\hline\hline %inserts double horizontal lines
		
		\diaghead(-2,1){aaaaaaa}{n}{k} & 1 & $\frac{n}{4}$ & $\frac{n}{2}$  & $\frac{3n}{4}$ & n \\ [0.5ex] % inserts table
			%heading
			\hline % inserts single horizontal line
			4 & 8.881784E-16 & 8.881784E-16 & 8.8818E-16 & 8.8818E-16 &8.8818E-16 \\ % inserting body of the table
			16 & 1.99770E-6 & 2.02060E-14 & 2.020606E-14 &2.020606E-14&2.042810E-14\\
			64 & 1.9708842E-5 & 4.993783E-13 & 4.9938E-13 &4.993783E-13&5.140338E-13\\
			256 & 7.34135E-5 & 1.18067E-11 & 1.18067E-11 &1.18067E-11&1.176681E-11\\
			1024 & 2.3177027E-4 & 2.04782E-10 & 1.98478E-10 &1.9847878E-10&2.00121E-10\\ [1ex] % [1ex] adds vertical space
			\hline %inserts single line
		\end{tabular}
	\caption{Похибки при різних $n$ i $k$}
		\label{table:nonlin} % is used to refer this table in the text
	\end{table}
\newpage
	\subsection{Приклад 2}
	\hspace{0.8cm}Розглядаємо рівняння
	$$\int_{0}^{1}\log|x-y|u(y)dy =\frac{2x^2\log|x|-2\log|x-1|(x^2-1)-2x-1}{4}$$
	Точний розв'язок даного рівняння має вигляд $u^*(x)=x$
	\begin{table}[ht]
		\centering 
		\begin{tabular}{c c c c c c } % centered columns (4 columns)
			\hline\hline %inserts double horizontal lines
			
			\diaghead(-2,1){aaaaaaa}{n}{k} & 1 & $\frac{n}{4}$ & $\frac{n}{2}$  & $\frac{3n}{4}$ & n \\ [0.5ex] % inserts table
			%heading
			\hline % inserts single horizontal line
			4 & 0.142393 & 0.142393 & 0.1423937 & 0.1423937 &0.1423937 \\ % inserting body of the table
			16 & 0.035737 & 0.0357365 & 0.0357365 &0.0357365&0.0357365\\
			64 & 0.00894708 &0.00894237 & 0.00894237 &0.00894237&0.00894237\\
			256 & 0.0022506 & 0.00223609 & 0.00223609 &0.00223609&0.00223609\\
			1024 & 7.7118E-4 & 5.590532E-4 & 5.59053E-4 &5.59053E-4&5.5905321665E-4\\ [1ex] % [1ex] adds vertical space
			\hline %inserts single line
		\end{tabular}
		\caption{Похибки при різних $n$ i $k$}
		\label{table:nonlin} % is used to refer this table in the text
	\end{table}
	\subsection{Приклад 3}
	\hspace{0.8cm}Розглядаємо рівняння
	$$\int_{0}^{1}\log|x-y|u(y)dy=-\dfrac{\left(12y^3-18y^2\right)\ln\left(\left|y-x\right|\right)+\left(18x^2-12x^3\right)\ln\left(\left|y-x\right|\right)-4y^3+}{36}$$$$\dfrac{+\left(9-6x\right)y^2+\left(18x-12x^2\right)y}{36}$$
		Точний розв'язок даного рівняння має вигляд $u^*(x)=x(1-x)$
	\begin{table}[ht]
		\centering 
		\begin{tabular}{c c c c c c } % centered columns (4 columns)
			\hline\hline %inserts double horizontal lines
			
			\diaghead(-2,1){aaaaaaa}{n}{k} & 1 & $\frac{n}{4}$ & $\frac{n}{2}$  & $\frac{3n}{4}$ & n \\ [0.5ex] % inserts table
			%heading
			\hline % inserts single horizontal line
			4 & 0.09689281 &0.09689281 & 0.09689281 & 0.09689281 &0.09689281 \\ % inserting body of the 
			16 & 0.03246286 & 0.032463147 & 0.032463147 &0.03246314722&0.03246314722\\
			64 & 0.00873409 &0.008736689 & 0.008736689 &0.008736689&0.008736689\\
			256 & 0.002215192 & 0.0022232 & 0.0022232 &00.0022232047&0.00222320\\
			1024 & 5.40425E-4 & 5.58247E-4 & 5.58247E-4 &5.582473E-4&5.582473E-4\\ [1ex] % [1ex] adds vertical space
			\hline %inserts single line
		\end{tabular}
		\caption{Похибки при різних $n$ i $k$}
		\label{table:nonlin} % is used to refer this table in the text
	\end{table}	
	\chapter{4. Розв'язання задачі Діріхле для рівняння Лапласа на площині}
	\hspace{0.8cm} В попередньому розділі, ми розглядали одновимірний випадок побудови ієрархічної матриці. Тепер проаналізуємо багатовимірний випадок і розглянемо розв'язання задачі Діріхле для рівняння Лапласа методом граничних елементів в $\mathbb{R}^2$. 
	\section{Внутрішня задача Діріхле}
	\hspace{0.8cm} Нехай $\Omega\subset\mathbb{R}^2$ - обмежена однозв'язна область з границею $\Gamma\subset C^2$.
	\par Знайти функцію $u$, яка гармоніча в $\Omega$, неперервна в $\bar{\Omega}$ і задовольняє граничну умову $$u=f \text{ на }\Gamma$$
	де $f$ - задана неперервна функція. $$\Updownarrow$$
	\par Знайти $u\in C^2(\Omega)\cap C(\bar{\Omega}):$
	$$\triangle u=0 \text{ в }\Omega$$
	$$u=f\text{ на }\Gamma$$
	де $f\in C(\Gamma)$ - задана.
	\par Фундаментальний розв'язок рівняння Лапласа при $\Omega\in\mathbb{R}^2$ має вигляд $$\Phi(x,y)=\frac{1}{2\pi}\log\frac{1}{\|x-y\|}=-\frac{1}{2\pi}\log\|x-y\|$$
	\par Нас цікавить проблема граничного інтегралу, тобто множина $\Omega$ буде підмноговидом. В нашому випадку,$\Omega$ є одновимірним підмноговидом $\mathbb{R}^2$ тобто є кривою.
	
	\begin{Def}
		Вважаємо, що задано $\varphi\in C(\Gamma)$. Функція $$u(x)=\int_{\Gamma}\varphi(y)\Phi(x,y)ds(y),  x\not\in\Gamma$$
		називається потенціалом простого шару.
	\end{Def}
	\par Зафіксуємо $n$ точок $p_0,...p_{n-1}\in \mathbb{R}^2$ і нехай $p_0:=p_n$. Означимо афінну параметризацію $$\gamma_i:[0,1]\rightarrow\mathbb{R}^2$$
	$$y\mapsto p_{i-1}(1-y)+p_iy$$
	для $i\in\{1,...,n\}$.
	\par Нехай для всіх $i,j\in\{0,...,n-1\}$ з $i\not=j$ виконується $p_i\not=p_j$. Тепер можемо визначити багатокутну криву
	$$\Gamma:=\bigcup_{i=1}^m\gamma_i([0,1])$$
	\begin{figure}[h]{
			\includegraphics{2_2}
		}
	\end{figure}
	\par На кривій $\Gamma$, можемо означити оператор потенціалу простого шару
	$$\Upsilon_{slp}[u](x):=-\frac{1}{2\pi}\int_{\Gamma}\log(\|x-y\|)u(y)dy$$
	і відповідну білінійну форму
	$$a_{slp}(u,v):=-\frac{1}{2\pi}\int_{\Gamma}v(x)\int_{\Gamma}\log(\|x-y\|)u(y)dydx$$
	\par Дискретизуємо $a_{slp}(\cdot,\cdot)$ кусково-постійними функціями $(\varphi_i)_{i=1}^n$ визначинеми як $$\varphi_i\circ\gamma_j=\delta_{ij}$$
	для $i,j\in I:={1,...,n}$.
	\par Коефіцієнти відповідних матриць задаються наступним чином $$G_{ij}=a_{slp}(\varphi_j,\varphi_i)=-\frac{1}{2\pi}\int_{\Gamma}\varphi_i(x)\int_{\Gamma}\log(\|x-y\|)\varphi_j(y)dydx$$
	$$=-\frac{1}{2\pi}\|p_i-p_{i-1}\| \|p_j-p_{j-1}\|\int_{0}^{1}\int_{0}^{1}\log(\|\gamma_i(x)-\gamma_j(y)\|)dydx$$
	\par Цей інтеграл можна знайти за допомогою квадратури Гауса, проте він має особливість, якщо $i=j$, тому для цього випадку порахуємо інтеграл точно:
	$$\gamma_i(x)-\gamma_i(y) = p_{i-1}(1-x)-p_ix-p_{i-1}(1-y)+p_iy=p_{i-1}(y-x)+p_i(y-x)=(p_{i-1}+p_i)(y-x)$$
	$$\int_{0}^{1}\int_{0}^{1}\log\|\gamma_i(x)-\gamma_i(y)\|dydx=\int_{0}^{1}\int_{0}^{1}\log|(\|p_{i-1}+p_i\||x-y|)dydx =$$$$ \log\|p_{i-1}+p_i\|+\int_{0}^{1}\int_{0}^{1}\log|x-y|dydx$$
	\par Тепер ми можемо побудувати ієрархічну матрицю так чк в попередньому розділі, замінивши логарифмічне ядро $g(x,y)=\log(\|x-y\|)$ відповідними апроксимаціями.
	\par Базисні функціх для нашої задачі мають вигляд:
	\newline 
	\begin{equation*}
	\varphi_i(x)=\begin{cases}
	1,\quad\text{якщо $ x\in \gamma_i[0,1]$}\\
	0,\quad\text{якщо $ x\not\in \gamma_i[0,1]$}
	\end{cases}
	\end{equation*}
	\newline
	$$f_i=\|p_i-p_{i-1}\|\int_{0}^{1}f(\gamma_i(y))dy$$
	\par Після знаходження $u_n$, розв'язок можна порахувати наступним чином:
	$$u(x) = -\frac{1}{2\pi}\sum_{i=1}^{n}\int_{\Gamma_i}\log\|x-y\|u(y)ds(y)=-\frac{1}{2\pi}\sum_{i=1}^{n}\|p_i-p_{i-1}\|\int_{0}^{1}\log\|x-\gamma_(y)\|u(\gamma_i(y))dy\approx$$$$ -\frac{1}{2\pi}\sum_{i=1}^{n}u_i\|p_i-p_{i-1}\|\int_{0}^{1}\log\|x-\gamma_i(y)\|dy$$
	\par Розширення на $n$-вимірний випадок вимагає зміни методу побудови кластерного дерева. Зокрема для побудови багатовимірного кластерного дерева застосовуємо метод бісекцій. Також розширюємо умову допустимості.
 	\section{Геометрична бісекція}
	\hspace{0.8cm} Для побудови багатовимірного кластерного дерева для заданої множини базисних функцій використовуємо метод геометричної бісекції.
	\par Складність геометричних операцій для їєрархічної матриці напряму пов'язана з кількістю листків блочного кластерного дерева, тому кластерне дерево повинне забезпечувати, що блоки стають допустимими якомога швидше. Допустимість блоку залежить від діаметрів носіїв базисних функцій і від відстаней між ними. Ми можемо спробувати вибрати кластерне дерево таким чином, щоб діаметри зменшувалися швидко.
	\par Для кожного $i\in I$ позначаємо носій відповідної базисної функції $\varphi_i$ як $\Omega_i:=supp(\varphi_i)$. Оскільки працювати з носіями функцій буде важко, ми вибираємо точку $x_i\in\Omega_i$ для кожного індекса $i\in I$ і надалі працюємо з цими точками.
	\par Побудова кластерного дерева починається з повної множини індексів $I$, яка є коренем кластерного дерева. Тоді ми застосовуємо відповідну техніку для знаходження непересічного поділу множини індексів і застосовуємо цей поділ для побудови дочірніх кластерів. Цю процедуру застосовуємо рекурсивно до до всіх синів доки множини індексів не є достатньо малими. 
	\par Ми хочемо поділити множину індексів $\hat t\in I$, що відповідає кластеру $t$. Для кожного індекса $i \in \hat t$, що відповідає точці $x_i\in\mathbb{R}^n$ можемо визначити
	$$a_l:=\min \{(x_i)_l : i\in \hat t\}$$
	$$b_l:=\max \{(x_i)_l : i\in \hat t\}$$
	для кожного $l\in \{1,...,n\}$. 
	\par Таким чином всі точки знаходяться в паралельній осі коробці $[a_1,b_1]\times...\times[a_n,b_n]$. Тепер є вибір: ми можемо розділити коробку в усіх напрямках координат одночасно (отримуємо $2^n$ підмножини) або ми можемо вибрати координатний напрямок найбільшої відстані і поділити коробку перпендикулярно до цього напрямку на дві підмножини.
	\par При першому підході, ми отримуємо, що діаметри субдомейнів поділені навпіл. Але це призводить до маленької кількості кластерів, а отже ми отримуємо маленьку кількість кандидатів, з яких будемо обирати при побудові поділу блоків.
	\par Другий підхід прзводить до побудови дерева з великою кількістю кластерів. Недоліком є те, що діаметри кластерів будуть збільшуватися в $\sqrt{
	1-\frac{3}{4n}}$ разів після одного кроку процедури. Водночас виконання $n$ кроків дасть нам  $2^n$ кластерів з діаметрами, поділеними навпіл, точно як і в першому підході.
	\section{Обмежувальні коробки}
	\hspace{0.8cm} Перевіряти умову допустимості для всієї області визначення може звбирати велику кількість ресурсів, ому ми шукаємо спрощену умову. Традиційним способом є визначення кіл  (в 2D) або сфер(3D) Чебишева для області визначення, оскільки діаметри і відстані між колами і сферами може бути порахована зі складністю $O(1)$. Однак ми застосовуємо простішу техніку: коробки, паралельні осям.
	\par Для кожного кластера $t\in \mathbb{T}_I$ визначаємо коробку паралельну осям $Q_t\subseteq\mathbb{R}^n$ так що виконується $\Omega_t\subseteq Q_t$. Цю коробку назвемо обмежувальною коробкою кластера $t$. 
	\par Замінюючи області визначення $\Omega_t$ s $\Omega_s$ в загальній умові допустимості більшими коробками $Q_t$ і $Q_s$, ми отримуємо наступну умову допустимості
	$max(diam(Q_{t}),diam(Q_{s}))\le \eta\cdot dist(Q_{t},Q_{s})$ 
	\begin{figure}[bh]{
			\includegraphics{2_0}
		}
	\end{figure}	
	\par Якщо $Q_t=[a_1,b_1]\times...\times[a_n,b_n]$ i $Q_s=[c_1,d_1]\times...\times[c_n,d_n]$, то діаметр і відстань рахуємо за наступними формулами
	$$diam(Q_t)=\left(\sum_{l=1}^{n}(b_l-a_l)^2\right)^\frac{1}{2}$$
	$$diam(Q_s)=\left(\sum_{l=1}^{n}(d_l-c_l)^2\right)^\frac{1}{2}$$
	$$dist(Q_t,Q_s)=\left(\sum_{l=1}^{n}dist([a_l,b_l],[c_l,d_l])^2\right)^\frac{1}{2}$$
	\par Ці величини можна порахувати зі складністю $O(1)$.
	\section{Інтерполяція}
	\subsection{Вироджене наближення}
	\hspace{0.8cm}В попередньому розділі для розкладу ядра використовувався розклад Тейлора. Тепер будемо використовувати інтерполяцію для побудови апроксимації:
	\begin{itemize}
		\item $(x_v)_{v\in K}$ - множина інтерполяційних точок в $\mathbb{R}^n$
		\item $(\mathcal{L}_v)_{v\in K}$ - відповідна функція Лагранжа, для якої виконується 
		$$\mathcal{L}_v(x_{\mu})=\sigma_{v,\mu}$$
		для всіх $v,\mu\in K$.
	\end{itemize} 
		\par Внаслідок інтерпрляції отримуємо
		$$\tilde{g}(x,y):=\sum_{v\in K}g(x_v,y)\mathcal{L}_v(x)$$
		\par Використовуючи цю апроксимацію матрицю $G$ замінюємо на матрицю $\hat G$, визначену наступним чином
		$$\tilde{G}_{ij}=\int_{\Omega}\varphi_i(x)\int_{\Omega}\tilde{g}(x,y)\varphi_j(y)dy dx=\sum_{v\in K}\int_{\Omega}\varphi_i(x)\mathcal{L}_v(x)dx\int_{\Omega}\varphi_j(y)g(x_v,y)dy=(AB^\top)_{ij}$$
		де відповідні матриці визначені наступним чином
		$$A_{iv}:=\int_{\Omega}\varphi_i(x)\mathcal{L}_v(x)dx$$
		$$B_{jv}:=\int_{\Omega}\varphi_j(x)\tilde{g}(x_v,y)dy$$
		\par Очевидно, що ранг матриці $\tilde{G}=AB^\top$ обмежений числом $K$, тож ми знайшли альтернативний метод для обчислення низькорівневих апроксимацій.
		\subsection{Апроксимація тензорним добутком на обмежувальних коробках}
		\hspace{0.8cm} Потрібно знайти множину інтерполяційних точок і відповідну множину функцій Лагранжа для кожного кластера $t\in\mathbb{T}_I$, такі що похибка апроксимації відповідної області визначення $\Omega_t$ є достатньо малою.
		\par  Застосовуємо наступне спрощення: замість наближення функції ядра на загальній підмножині $\Omega_t\in\mathbb{R}^n$, ми апроксимуємо її на обмежувальній коробці $Q_t\supseteq\Omega_t$.
		\par Оскільки обмежувальна коробка $Q_t$ є тензорним добутком інтервалів, застосовуємо інтерполяцію на інтервалах. Для інтервала [-1,1], хорошим вибором є точки Чебишева m-того порядку
		$$(x_v)_{v=0}^m=\left(cos\left(\frac{2v+1}{2m+2}\pi\right)\right)_{v=0}^m$$
		\par Поліноми Лагранжа мають вигляд
		$$\mathcal{L}_v(x)=\prod_{\mu=0,\mu\not=v}^{m}\frac{x-x_\mu}{x_v-x_\mu}$$
		\par Відповідний інтерполяційний оператор задається наступним чином
		$$\mathcal{J}_m:C[-1,1]\rightarrow\mathcal{P}_m$$
		$$f\mapsto\sum_{v=0}^{m}f(x_v)\mathcal{L}_v$$
		
		\begin{figure}[h]{
				\includegraphics{2_1}
			}
		\end{figure}
	\par Для того, щоб отримати інтерполяційний оператор для непорожнього інтервалу $[a,b]$, ми використовуємо афінні трансформацію
	$$\Phi_{[a,b]}:[-1,1]\rightarrow [a,b]$$
	$$x\mapsto \frac{b+a}{2}+\frac{b-a}{2}x$$
	і визначаємо трансформований інтерполяційний оператор $\mathcal{J}_m^{[a,b]}:C[a,b]\rightarrow\mathcal{P}_m$ як
	$$\mathcal{J}_m^{[a,b]}[f] := (\mathcal{J}_m[f\circ\Phi_{[a,b]}])\circ \Phi_{[a,b]}^{-1}=\sum_{v=0}^{m}f(\Phi_{[a,b]}(x_v))\mathcal{L}_v\circ\Phi_{[a,b]}^{-1}$$
	\par Визначаємо трансформовані інтерполяційні точки
	$$x_v^{[a,b]}:=\Phi_{[a,b]}(x_v)=\frac{b+a}{2}+\frac{b-a}{2}x_v$$
	і відповідні функції Лагранжа
	$$\mathcal{L}_v^{[a,b]}:=\mathcal{L}_v\circ\Phi_{[a,b]}^{-1}$$
	\par Зазначимо, що
	$$\mathcal{L}_v^{[a,b]}(x_\mu^{[a,b]})=\mathcal{L}_v\circ\Phi_{[a,b]}^{-1}(\Phi_{[a,b]}(x_\mu))=\mathcal{L}_v(x_\mu)=\sigma_{v\mu}$$
	правдиве для всіх $v,\mu\in\{0,...,m\}$. Звідси отримуємо, що
	$$\mathcal{L}_v^{[a,b]}(x)=\prod_{\mu=0,\mu\not=v}^{m}\frac{x-x_\mu^{[a,b]}}{x_v^{[a,b]}-x_\mu^{[a,b]}}$$
	\par В n-вимірному випадку, областю визначення інтерполяції є обмежувальна коробка, паралельна до осей $Q_t=[a_1,b_1]\times...\times[a_n,b_n]$. Оскільки область визначення має структуру тензорного добутку, напряму використовуємо інтерполяцію тензорним добутком, тобто визначаємо 
	$$\mathbb{J}_m^t:=\mathcal{J}_m^{[a_1,b_1]}\otimes...\otimes\mathcal{J}_m^{[a_n,b_n]}$$ 
	\begin{center}
		\includegraphics[scale=0.5]{2_6}
	\end{center}

	Визначаємо
	\begin{itemize}
		\item множину мультиіндексів
		$$K:=\{v\in\mathbb{N}_0^n:v_i\le m \mbox{ для всіх } i\in \{1,...,d\}\}=\{0,...m\}^n$$
		\item відповідні точки інтерполяції
		$$x_v^t:=(x_{v_1}^{[a_1,b_1]},...,x_{v_n}^{[a_n,b_n]})$$
		\item поліноми Лагранжа
		$$\mathcal{L}_v^t:=\mathcal{L}_{v_1}^{[a_1,b_1]}\otimes...\otimes\mathcal{L}_{v_n}^{[a_n,b_n]}$$
	\end{itemize}
	Тепер ми можемо визначити $\mathcal{J}_m^t$ в знайомій формі
	$$\mathcal{J}_m^t[f](x)=\sum_{v\in K}f(x_v^t)\mathcal{L}_v^t(x)$$
	Оцінити $\mathcal{L}_v^t$ досить просто
	$$\mathcal{L}_v^t(x)=\left(\mathcal{L}_{v_1}^{[a_1,b_1]}\otimes...\otimes\mathcal{L}_{v_n}^{[a_n,b_n]}\right)(x)=\prod_{i=1}^{n}\mathcal{L}_{v_i}^{[a_i,b_i]}(x_i)=\prod_{i=1}^{n}\prod_{\mu=0,\mu\not=v_i}^{m}\frac{x_i-x_\mu^{[a_i,b_i]}}{x_{v_i}^{[a_i,b_i]}-x_\mu^{[a_i,b_i]}}$$
	\subsection{Побудова апроксимації низького рангу}
	\hspace{0.8cm} Розглянемо допустиму пару кластерів $(t,s)$. Допустимість каже, що виконується наступна умова
	$$\min\{diam(Q_T),diam(Q_s)\le \nu dist(Q_t,Q_s)\}$$
	\par Якщо $diam(Q_t)\le diam(Q_s)$, то ми застосовуємо інтерполяцію до першого аргумента функції ядра. Відповідний блок матриці має вигляд $(AB)^\top$, i ми обчислюємо матриці $A^{t,s}$ та $B^{t,s}$ наступним чином
	$$A_{iv}^{t,s}=\int_{\Omega}\varphi_i(x)\mathcal{L}_v^t(x)dx$$
	$$B_{jv}^{t,s}=\int_{\Omega}\varphi_j(y)g(x_v^t,y)dy$$
	де $x_v^t$ i $\mathcal{L}_v^t$ - перетворені інтерполяційні точки і поліноми Лагранжа відповідно.
	\par Якщо $diam(Q_s)\le diam(Q_t)$, то ми застосовуємо інтерполяцію до другого аргумента функції ядра i обчислюємо матриці $A^{t,s}$ та $B^{t,s}$:
	$$A_{iv}^{t,s}=\int_{\Omega}\varphi_i(x)g(x,x_v^s)dx$$
	$$B_{jv}^{t,s}=\int_{\Omega}\varphi_j(y)\mathcal{L}_v^s(y)dy$$
	
	\par Потрібно обчислити матриці
	$$A_{iv}^{(t,s)}=\int_{\Gamma}\varphi_i(x)\mathcal{L}_v^t(x)dx=\|p_i-p_{i-1}\|\int_{0}^{1}\mathcal{L}_v^t(\gamma_i(x))dx$$
	$$B_{jv}^{t,s}=-\frac{1}{2\pi}\int_{\Gamma}\varphi_j(y)\log(\|x_v^t-y\|)dy=-\frac{1}{2\pi}\|p_j-p_{j-1}\|\int_{0}^{1}\log(\|x_v^t-\gamma_j(y)\|)dy$$ 
	
	\section{Чисельні експерименти}
	\hspace{0.8cm}В усіх наведених експериментах, розглядаємо випадок $n_{min}=(m+1)^2$.
	\subsection{Приклад 1}
	\hspace{0.8cm}Розглядаємо рівняння
	$$f(x)=1$$ 
	на області $(\cos(t), \sin(t))$.
	\begin{center}
	\includegraphics[scale=0.5]{2_3}
	\end{center}
	\begin{table}[ht]
		\centering 
		\begin{tabular}{c c c c c c c } % centered columns (4 columns)
			\hline\hline %inserts double horizontal lines
			
			\diaghead(-2,1){aaaaaaa}{n}{m} & 1 & 2 & 4 &8 & $\frac{n}{2}$ & n \\ [0.5ex] % inserts table
			%heading
			\hline % inserts single horizontal line
			16 & 0.023391& 0.023391 & 0.023391 & 0.023391&0.023391 &0.023391 \\ % inserting body of the table
			128 & 0.539404& 0.020159 & 0.002882 &0.002868 &0.002868 &0.002868\\
			512 &0.978209 & 0.549960& 0.001555 &6.97650E-4 &6.97613E-4&6.97613E-4\\
			1024 & 0.991999 & 0.219098& 8.67033E-4&2.86320E-4 &2.86073E-4&2.86073E-4\\
			2048 & 1.221710& 1.018441& 0.003504&3.803751E-5&3.78993E-5&3.78993E-5
			\\ [1ex] % [1ex] adds vertical space
			\hline %inserts single line
		\end{tabular}
		\caption{Похибки при різних $n$ i $m$}
		\label{table:nonlin} % is used to refer this table in the text
	\end{table}
	\subsection{Приклад 2}
	\hspace{0.8cm}Розглядаємо рівняння
	$$f(x)=\frac{x_1+x_2}{x_1^2+x_2^2}$$ 
	на області $(\cos(t+3)+1, \sin(t)+1)$.
	\begin{center}
	\includegraphics[scale=0.5]{2_4}
	\end{center}
	\begin{table}[ht]
		\centering 
		\begin{tabular}{c c c c c c c} % centered columns (4 columns)
			\hline\hline %inserts double horizontal lines
			
			\diaghead(-2,1){aaaaaaa}{n}{m} & 1 & 2 & 4 & 8& $\frac{n}{2}$ & n \\ [0.25ex] % inserts table
			%heading
			\hline % inserts single horizontal line
			16 & 0.025115& 0.025115 & 0.025115& 0.025115& 0.025115& 0.025115  \\ % inserting body of the table
			128 & 0.0329124& 0.0056143 & 1.97673E-4&1.98081E-4 &1.98081E-4&1.98081E-4\\
			512 &0.066451 & 0.001317& 4.19164E-6 &3.24162E-6&3.24165E-6&3.241653E-6\\
			1024 & 0.071486& 0.0013674& 3.63543E-6& 3.33958E-7 &3.33818E-7&3.33818E-7\\
			2048 & 0.077750& 0.001486& 3.03901E-6&2.11734E-8 &2.11614E-8&2.11614E-8
			\\ [0.5ex] % [1ex] adds vertical space
			\hline %inserts single line
		\end{tabular}
		\caption{Похибки при різних $n$ i $m$}
		\label{table:nonlin} % is used to refer this table in the text
	\end{table}
\subsection{Приклад 3}
\hspace{0.8cm}Розглядаємо рівняння
$$f(x)=\log\|x-x^*\|$$ 
на області $\Omega = (\cos(t+10), \sin(t)), x^*\not \in \Omega$.
\begin{center}
\includegraphics[scale=0.5]{2_5}
\end{center}
\begin{table}[ht]
	\centering 
	\begin{tabular}{c c c c c c c} % centered columns (4 columns)
		\hline\hline %inserts double horizontal lines
		
		\diaghead(-2,1){aaaaaaa}{n}{m} & 1 & 2 & 4 & 8& $\frac{n}{2}$ & n \\ [0.25ex] % inserts table
		%heading
		\hline % inserts single horizontal line
		16 & 0.006358& 0.005982& 0.005982 & 0.005982 & 0.005982 &0.005982  \\ % inserting body of the table
		128 & 0.005312& 2.11039E-4 & 1.38351E-5&1.38039E-5 &1.38039E-5&1.38039E-5\\
		512 &0.002525 & 7.28675E-5& 5.84060E-7 &2.10061E-7&2.10046E-7&2.10046E-7\\
		1024 & 0.002373 &6.46704E-5 & 4.55549E-7& 2.19112E-8 &2.17739E-8&2.17739E-8\\
		2048 & 0.002462& 7.13012E-5& 4.38285E-8 &1.01539E-9 &8.32696E-10&8.32696E-10
		\\ [0.5ex] % [1ex] adds vertical space
		\hline %inserts single line
	\end{tabular}
	\caption{Похибки при різних $n$ i $m$}
	\label{table:nonlin} % is used to refer this table in the text
\end{table}

\begin{table}[ht]
	\centering 
	\begin{tabular}{|c| c| c| c| c|} % centered columns (4 columns)
		\hline%inserts double horizontal lines
		
	
		& \multicolumn{2}{c|}{Обчислення з ієрархічними матрицями} &\multicolumn{2}{c|}{Обчислення з методом Гауса } \\
		
		\raisebox{1.5ex}[0cm][0cm]{n}& похибка &час & похибка & час \\ [0.25ex] % inserts table
		%heading
		\hline % inserts single horizontal line
		16 & 0.0059827717& 308ms& 0.0059827717 & 156ms  \\ % inserting body of the table
		128 & 1.38351742E-5& 2747ms & 1.380390913E-5&2281ms \\
		512 &5.8406019E-7 & 11844ms & 2.10046807E-7 &20133ms\\
		1024 & 4.555495E-7 &30741ms& 2.17744124E-8& 70600ms \\
		2048 & 4.38285E-8& 88427ms& 4.88285E-9 & 274826ms
		\\ [0.5ex] % [1ex] adds vertical space
		\hline %inserts single line
	\end{tabular}
	\caption{Порівняння тривалості виконання методу Гальоркіна з використанням ієрархічних матриць при m=4 з використанням метода Гауса}
	\label{table:nonlin} % is used to refer this table in the text
\end{table}
	\chapter{Висновок}
	\hspace{0.8cm} В цій роботі розглянуто основні принципи побудови та використання $\mathcal{H}$-матриць. Описано такі ключові поняття як дерево, кластерне дерево та блочне кластерне дерево, які лягли в основу означення структури ієрархічної матриці. Також розглянуто відповідні структури через які ієрархічні матриці реалізують програмно: rkmatrix, fullmatrix та supermatrix. Наведено алгоритми реалізації блочного кластерного дерева i методу спряжених градієнтів.
	\par Застосування $\mathcal{H}$-матриць розглянуто на прикладі методу скінченних елементів (BEM). У даному прикладі застосовується метод Галеркіна та метод спряжених градієнтів. Розглянуто побудову $\mathcal{H}$-матриць для двовимірного випадку на прикладі задачі Діріхле для рівняння Лапласа. Проведений аналіз результатів.
	\newpage
	\begin{thebibliography}{00}
	\normalsize{
		\bibitem{HM}
	    	Steffen B\"orm {\it Hierarchical Matrices} / Lars Grasedyck, Wolfgang Hackbusch --- електронний ресурс, 2005. --- 136 c.
		\bibitem{Diss}
			Mohammad Izadi {\it Hierarchical Matrix Techniques on Massively Parallel Computers. Dissertation}---K.: Max Planck Institute for Mathematics in the Sciences,2012.--- 212 c.
		\bibitem{Descrete}
			Нікольський Ю.В. {\it Дискретна математика} / Пасічник В.В., Щербина Ю.М.---К.: Видавнича група BHV,2007.---368 c.
		\bibitem{Wolfg}
			 Wolfgang Hackbusch {\it Hierarchical Matrices: Algorithms and Analysis}---K.: Springer-Verlag,2015.--- 505 c.
		
		\bibitem{fghj}
			Lin Lin {\it Fast construction of hierarchical matrix representation from matrix–vector
			multiplication } /  Jianfeng Lu, Lexing Ying --- K.: Journal of Computational Physics 230 4071–4087,2011.---17 c.
		\bibitem{Gradient}
			Jonathan Richard Shewchuk {\it An Introduction to the Conjugate Gradient Method Without the Agonizing Pain }---K.:School of Computer Science, Pittsburg,PA 15213,1994.---64 c. 	 
	}
	\end{thebibliography}	
\end{document}